# ğŸ“Š Preprocesamiento de Datasets - Streamlit App

AplicaciÃ³n web interactiva desarrollada con Streamlit que presenta tres ejercicios completos de preprocesamiento de datos para Machine Learning.

## ğŸ¯ DescripciÃ³n del Proyecto

Este proyecto contiene tres ejercicios prÃ¡cticos que demuestran diferentes tÃ©cnicas de preprocesamiento de datos:

1. **ğŸš¢ Ejercicio 1: Dataset Titanic** - PredicciÃ³n de supervivencia
2. **ğŸ“š Ejercicio 2: Student Performance** - PredicciÃ³n de notas finales
3. **ğŸŒ¸ Ejercicio 3: Iris Dataset** - ClasificaciÃ³n de especies de flores

## ğŸš€ InstalaciÃ³n Local

### Prerequisitos

- Python 3.8 o superior
- pip (gestor de paquetes de Python)

### Pasos de InstalaciÃ³n

1. **Clonar o descargar el proyecto**

```bash
cd datasets_processing
```

2. **Crear un entorno virtual (recomendado)**

```bash
# En Windows
python -m venv venv
venv\Scripts\activate

# En macOS/Linux
python3 -m venv venv
source venv/bin/activate
```

3. **Instalar las dependencias**

```bash
pip install -r requirements.txt
```

4. **Ejecutar la aplicaciÃ³n**

```bash
streamlit run app.py
```

La aplicaciÃ³n se abrirÃ¡ automÃ¡ticamente en tu navegador en `http://localhost:8501`

## ğŸ“¦ Estructura del Proyecto

```
datasets_processing/
â”‚
â”œâ”€â”€ app.py                          # AplicaciÃ³n principal de Streamlit
â”œâ”€â”€ requirements.txt                # Dependencias del proyecto
â”œâ”€â”€ README.md                       # Este archivo
â”‚
â”œâ”€â”€ ejercicio_1/
â”‚   â”œâ”€â”€ ejercicio1.py              # Script original del ejercicio 1
â”‚   â””â”€â”€ Titanic-Dataset.csv        # Dataset del Titanic
â”‚
â”œâ”€â”€ ejercicio_2/
â”‚   â”œâ”€â”€ ejercicio2.py              # Script original del ejercicio 2
â”‚   â””â”€â”€ student-mat.csv            # Dataset de rendimiento estudiantil
â”‚
â””â”€â”€ ejercicio_3/
    â””â”€â”€ ejercicio3.py              # Script original del ejercicio 3
```

## ğŸŒ Deployment en Streamlit Cloud

### OpciÃ³n 1: Deployment desde GitHub

1. **Subir el proyecto a GitHub**

```bash
# Inicializar repositorio git (si no existe)
git init

# Agregar archivos
git add .

# Hacer commit
git commit -m "Initial commit - Datasets Processing App"

# Conectar con tu repositorio remoto
git remote add origin https://github.com/TU_USUARIO/TU_REPOSITORIO.git

# Subir los cambios
git push -u origin main
```

2. **Deployment en Streamlit Cloud**

   - Ve a [share.streamlit.io](https://share.streamlit.io)
   - Inicia sesiÃ³n con tu cuenta de GitHub
   - Click en "New app"
   - Selecciona tu repositorio
   - ConfiguraciÃ³n:
     - **Main file path**: `app.py`
     - **Python version**: 3.9 o superior
   - Click en "Deploy"

### OpciÃ³n 2: ConfiguraciÃ³n Avanzada

Si necesitas configuraciones adicionales, puedes crear archivos:

**`.streamlit/config.toml`** (opcional):

```toml
[theme]
primaryColor = "#1f77b4"
backgroundColor = "#ffffff"
secondaryBackgroundColor = "#f0f2f6"
textColor = "#262730"
font = "sans serif"

[server]
maxUploadSize = 200
enableXsrfProtection = true
```

**`.gitignore`**:

```
# Python
__pycache__/
*.py[cod]
*$py.class
*.so
.Python
venv/
env/
ENV/

# Streamlit
.streamlit/secrets.toml

# IDE
.vscode/
.idea/
*.swp
*.swo

# OS
.DS_Store
Thumbs.db
```

## ğŸ“Š CaracterÃ­sticas de la AplicaciÃ³n

### Ejercicio 1: Dataset Titanic

- âœ… Limpieza de datos (eliminaciÃ³n de columnas irrelevantes)
- âœ… ImputaciÃ³n de valores nulos (media y moda)
- âœ… CodificaciÃ³n de variables categÃ³ricas (LabelEncoder)
- âœ… EstandarizaciÃ³n de variables numÃ©ricas (StandardScaler)
- âœ… DivisiÃ³n train/test (70/30)
- âœ… Visualizaciones de supervivencia

### Ejercicio 2: Student Performance

- âœ… EliminaciÃ³n de duplicados
- âœ… One-Hot Encoding para variables categÃ³ricas
- âœ… NormalizaciÃ³n MinMax (rango 0-1)
- âœ… AnÃ¡lisis de correlaciÃ³n entre notas
- âœ… DivisiÃ³n train/test (80/20)
- âœ… Visualizaciones de distribuciÃ³n y correlaciÃ³n

### Ejercicio 3: Iris Dataset

- âœ… Carga desde sklearn.datasets
- âœ… EstandarizaciÃ³n completa (StandardScaler)
- âœ… AnÃ¡lisis estadÃ­stico detallado
- âœ… DivisiÃ³n train/test (70/30)
- âœ… Visualizaciones de dispersiÃ³n por clase
- âœ… Matriz de correlaciÃ³n entre caracterÃ­sticas

## ğŸ› ï¸ TecnologÃ­as Utilizadas

- **Streamlit**: Framework para aplicaciones web de datos
- **Pandas**: ManipulaciÃ³n y anÃ¡lisis de datos
- **NumPy**: ComputaciÃ³n numÃ©rica
- **Scikit-learn**: Preprocesamiento y machine learning
- **Matplotlib**: VisualizaciÃ³n de datos
- **Seaborn**: VisualizaciÃ³n estadÃ­stica

## ğŸ“ Notas Importantes

1. **Archivos de datos**: AsegÃºrate de que los archivos CSV estÃ©n en sus respectivas carpetas:

   - `ejercicio_1/Titanic-Dataset.csv`
   - `ejercicio_2/student-mat.csv`

2. **Dataset Iris**: Se carga automÃ¡ticamente desde scikit-learn, no requiere archivo CSV.

3. **Memoria**: La aplicaciÃ³n carga los datasets en memoria, ideal para datasets pequeÃ±os y medianos.

## ğŸ› SoluciÃ³n de Problemas

### Error: "No se encontrÃ³ el archivo CSV"

- Verifica que los archivos CSV estÃ©n en las carpetas correctas
- AsegÃºrate de ejecutar la app desde el directorio raÃ­z del proyecto

### Error de dependencias

```bash
pip install --upgrade pip
pip install -r requirements.txt --force-reinstall
```

### Puerto ya en uso

```bash
streamlit run app.py --server.port 8502
```
